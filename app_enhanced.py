import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import seaborn as sns
import joblib
import os

from reportlab.platypus import (
    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle,
    Image as RLImage, PageBreak
)
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import inch
from reportlab.lib import colors
from datetime import datetime

st.set_page_config(
    page_title="Data Drift Research Dashboard",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
.stApp { background-color: #1e1e1e !important; }
section[data-testid="stMain"] { background-color: #1e1e1e !important; }
.block-container { background-color: #1e1e1e !important; }
[data-testid="stSidebar"] { background-color: #111827 !important; }
[data-testid="stSidebar"] * { color: #ffffff !important; }
h1, h2, h3, h4 { color: #ffffff !important; }
p, li, span, label { color: #e0e0e0 !important; }
.stMarkdown { color: #e0e0e0 !important; }
.alert-green {
    background-color: #064e3b;
    border: 2px solid #10b981;
    border-radius: 10px;
    padding: 1.2rem;
    margin: 1rem 0;
    color: #d1fae5 !important;
}
.alert-blue {
    background-color: #1e3a5f;
    border: 2px solid #3b82f6;
    border-radius: 10px;
    padding: 1.2rem;
    margin: 1rem 0;
}
.alert-purple {
    background-color: #2d1b69;
    border: 2px solid #8b5cf6;
    border-radius: 10px;
    padding: 1.2rem;
    margin: 1rem 0;
}
.alert-orange {
    background-color: #451a03;
    border: 2px solid #f97316;
    border-radius: 10px;
    padding: 1.2rem;
    margin: 1rem 0;
}
.stat-box {
    background-color: #1f2937;
    border-left: 5px solid #3b82f6;
    border-radius: 10px;
    padding: 1rem 1.2rem;
    margin: 0.7rem 0;
}
.stat-label { font-size: 0.75rem; color: #9ca3af !important; font-weight: 700; text-transform: uppercase; letter-spacing: 1px; }
.stat-value { font-size: 2.5rem; font-weight: 900; color: #ffffff !important; line-height: 1.1; }
.stat-value-red { font-size: 2.5rem; font-weight: 900; color: #ff6b6b !important; line-height: 1.1; }
.method-step {
    background-color: #1f2937;
    border-left: 4px solid #8b5cf6;
    border-radius: 8px;
    padding: 1rem 1.2rem;
    margin: 0.5rem 0;
}
.recommendation-box {
    background: linear-gradient(135deg, #064e3b, #065f46);
    border: 2px solid #10b981;
    border-radius: 12px;
    padding: 1.5rem;
    margin: 1rem 0;
}
.finding-card {
    background-color: #1f2937;
    border: 1px solid #374151;
    border-radius: 10px;
    padding: 1.2rem;
    margin: 0.5rem 0;
    border-top: 3px solid #3b82f6;
}
</style>
""", unsafe_allow_html=True)

# ---- SIDEBAR ----
st.sidebar.markdown("""
<div style='background: linear-gradient(135deg, #1e3a5f, #3b82f6); padding: 1.5rem; border-radius: 12px; margin-bottom: 1.5rem; text-align: center;'>
    <h2 style='color: white; margin: 0;'>üìä Research Project</h2>
    <p style='color: #bfdbfe; margin: 0.5rem 0 0 0; font-size: 0.9rem;'>ML Model Reliability<br>Under Data Drift</p>
</div>
""", unsafe_allow_html=True)

st.sidebar.markdown("### üß≠ Navigation")
page = st.sidebar.radio(
    "Menu",
    ["üè† Project Overview",
     "üî¨ Methodology",
     "üîÆ Live Prediction",
     "üìà Research Results",
     "üéØ Model Robustness",
     "üíº Industry Value"],
    label_visibility="collapsed"
)

st.sidebar.markdown("---")
st.sidebar.markdown("### üìä Project Stats")

try:
    if os.path.exists('results/experiments/covariate_drift_results.csv'):
        results = pd.read_csv('results/experiments/covariate_drift_results.csv')
        n_models = results['model'].nunique()
        n_experiments = len(results)
        baseline = results[results['drift_magnitude'] == 0.0]
        high_drift = results[results['drift_magnitude'] == results['drift_magnitude'].max()]
        avg_degradation = (baseline['accuracy'].mean() - high_drift['accuracy'].mean()) * 100

        st.sidebar.markdown(f"""
        <div class='stat-box'>
            <div class='stat-label'>Models Tested</div>
            <div class='stat-value'>{n_models}</div>
        </div>
        <div class='stat-box'>
            <div class='stat-label'>Experiments Run</div>
            <div class='stat-value'>{n_experiments}</div>
        </div>
        <div class='stat-box' style='border-left-color: #ef4444;'>
            <div class='stat-label'>Avg Performance Drop</div>
            <div class='stat-value-red'>{avg_degradation:.1f}%</div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.sidebar.info("Run experiments first")
except:
    st.sidebar.warning("Run experiments first")

st.sidebar.markdown("---")
st.sidebar.markdown("### ‚úÖ Research Progress")
checks = [
    ("Baseline Models Trained", True),
    ("Drift Experiments", os.path.exists('results/experiments/covariate_drift_results.csv')),
    ("Detection Analysis", os.path.exists('results/experiments/drift_detection_results.pkl')),
    ("Results Summary", os.path.exists('results/experiments/summary_report.txt'))
]
for label, done in checks:
    st.sidebar.markdown(f"{'‚úÖ' if done else '‚è≥'} {label}")

st.sidebar.markdown("---")
st.sidebar.markdown("""
<div style='background:#1f2937; padding:1rem; border-radius:8px; border:1px solid #374151;'>
<p style='color:#f59e0b !important; font-weight:700; margin:0 0 0.5rem 0;'>üí° Why This Matters</p>
<p style='color:#d1d5db !important; font-size:0.8rem; margin:0;'>73% of ML models degrade within 6 months. This project provides systematic drift detection and model robustness analysis.</p>
</div>
""", unsafe_allow_html=True)

st.sidebar.markdown("---")
st.sidebar.caption("üìö NCI Master's Project | 2026")


# ===========================================================
# PAGE: PROJECT OVERVIEW
# ===========================================================
if page == "üè† Project Overview":
    st.title("üìä Data Drift Impact on ML Model Performance")
    st.markdown("### *An Empirical Study of Production Model Reliability*")

    st.markdown("""
    <div class='alert-green'>
        <h4 style='color:#6ee7b7 !important; margin:0 0 0.5rem 0;'>üéØ Research Objective</h4>
        <p style='color:#d1fae5 !important; margin:0;'>
        While most ML research focuses on <b>maximizing accuracy</b>, this project studies
        <b>model reliability after deployment</b>. We systematically measure how models degrade
        under data drift ‚Äî the #1 cause of ML failures in production systems.
        </p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("### üéì Novel Contribution")
        st.markdown("""
        - **Beyond accuracy**: Degradation analysis
        - **Comparative study**: 4+ models tested
        - **Quantified impact**: Drift magnitude effects
        - **Detection methods**: Early warning systems
        """)
    with col2:
        st.markdown("### üè≠ Industry Problem")
        st.markdown("""
        - Silent model failures cost $15B/year
        - 60-70% performance drops common
        - No standard monitoring
        - Manual intervention required
        """)
    with col3:
        st.markdown("### üí° Research Questions")
        st.markdown("""
        **RQ1**: How does drift affect performance?

        **RQ2**: Which models are most robust?

        **RQ3**: Can we detect drift early?

        **RQ4**: What is the degradation pattern?
        """)

    st.markdown("---")
    st.markdown("### üìã Methodology Overview")
    tab1, tab2, tab3 = st.tabs(["Phase 1: Baseline", "Phase 2: Drift Simulation", "Phase 3: Analysis"])
    with tab1:
        st.markdown("""
        - Dataset: IBM Telco Customer Churn (7,043 customers)
        - Models: Logistic Regression, Random Forest, XGBoost, SVM
        - Metrics: Accuracy, Precision, Recall, F1, ROC-AUC
        - Split: 80% train / 20% test with stratification
        """)
    with tab2:
        st.markdown("""
        - **Covariate Drift**: Shift feature distributions using Gaussian noise + mean shift
        - **Prior Drift**: Change class ratios
        - **Concept Drift**: Alter feature-target relationships
        - Multiple magnitudes (0.0 ‚Üí 1.0) tested per drift type
        """)
    with tab3:
        st.markdown("""
        - Performance tracking across drift levels
        - Model comparison and robustness ranking
        - Statistical drift detection (KS test, PSI)
        - Degradation pattern identification
        """)


# ===========================================================
# PAGE: METHODOLOGY (NEW ‚Äî Answers professor's question)
# ===========================================================
elif page == "üî¨ Methodology":
    st.title("üî¨ Research Methodology")
    st.markdown("### *How We Simulated Data Drift & Evaluated Model Robustness*")

    st.markdown("""
    <div class='alert-blue'>
        <h4 style='color:#93c5fd !important; margin:0 0 0.5rem 0;'>üìå Why Methodology Matters</h4>
        <p style='color:#bfdbfe !important; margin:0;'>
        This section explains exactly <b>how data drift was simulated</b>, <b>which features were drifted</b>,
        and <b>how models were evaluated</b> ‚Äî making our results reproducible and scientifically defensible.
        </p>
    </div>
    """, unsafe_allow_html=True)

    # --- STEP 1: Dataset ---
    st.markdown("## Step 1 ‚Äî Dataset")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.markdown("""
        <div class='stat-box'>
            <div class='stat-label'>Dataset</div>
            <div style='color:#60a5fa; font-size:1.1rem; font-weight:700;'>IBM Telco Churn</div>
        </div>""", unsafe_allow_html=True)
    with col2:
        st.markdown("""
        <div class='stat-box'>
            <div class='stat-label'>Total Records</div>
            <div class='stat-value'>7,043</div>
        </div>""", unsafe_allow_html=True)
    with col3:
        st.markdown("""
        <div class='stat-box'>
            <div class='stat-label'>Features Used</div>
            <div class='stat-value'>5</div>
        </div>""", unsafe_allow_html=True)
    with col4:
        st.markdown("""
        <div class='stat-box'>
            <div class='stat-label'>Train / Test Split</div>
            <div style='color:#60a5fa; font-size:1.5rem; font-weight:700;'>80 / 20</div>
        </div>""", unsafe_allow_html=True)

    st.markdown("### Features Included in the Study")
    feature_data = {
        "Feature": ["tenure", "MonthlyCharges", "TotalCharges", "Contract", "InternetService"],
        "Type": ["Numeric", "Numeric", "Numeric", "Categorical", "Categorical"],
        "Drifted?": ["‚úÖ Yes", "‚úÖ Yes", "‚úÖ Yes", "‚ùå No (encoded)", "‚ùå No (encoded)"],
        "Why It Drifts in Real Life": [
            "Customer base ages ‚Äî avg tenure increases over time",
            "Price changes, promotions affect charge distributions",
            "Cumulative charges shift as pricing changes",
            "Contract preferences change seasonally",
            "Technology adoption changes service mix"
        ]
    }
    st.dataframe(pd.DataFrame(feature_data), use_container_width=True, hide_index=True)

    st.markdown("---")

    # --- STEP 2: Drift Simulation ---
    st.markdown("## Step 2 ‚Äî How Data Drift Was Simulated")

    st.markdown("""
    <div class='alert-purple'>
        <h4 style='color:#c4b5fd !important; margin:0 0 0.5rem 0;'>üß™ Drift Simulation Technique: Covariate Shift via Gaussian Noise + Mean Shift</h4>
        <p style='color:#ede9fe !important; margin:0;'>
        We applied <b>controlled Gaussian noise injection</b> combined with a <b>mean shift</b> to all numeric features.
        This simulates real-world distribution changes without altering the underlying data labels ‚Äî
        mimicking what happens when customer behaviour changes but the churn definition stays the same.
        </p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### üìê The Drift Formula")
        st.markdown("""
        <div class='method-step'>
            <p style='color:#c4b5fd !important; font-family:monospace; font-size:1rem; margin:0;'>
            X_drifted = X + (magnitude √ó œÉ √ó Œµ) + (magnitude √ó Œº √ó shift_factor)
            </p>
            <p style='color:#ede9fe !important; margin:0.5rem 0 0 0; font-size:0.85rem;'>
            Where:<br>
            ‚Ä¢ <b>X</b> = original feature values<br>
            ‚Ä¢ <b>magnitude</b> = drift level (0.0 to 1.0)<br>
            ‚Ä¢ <b>œÉ</b> = standard deviation of feature<br>
            ‚Ä¢ <b>Œµ</b> = Gaussian noise ~ N(0,1)<br>
            ‚Ä¢ <b>Œº</b> = mean of feature<br>
            ‚Ä¢ <b>shift_factor</b> = 0.1 (10% mean shift per unit)
            </p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("### üìä Drift Levels Tested")
        drift_levels = pd.DataFrame({
            "Drift Magnitude": [0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0],
            "Interpretation": [
                "Baseline ‚Äî no drift",
                "Very mild ‚Äî minor seasonal variation",
                "Mild ‚Äî small market shift",
                "Moderate ‚Äî noticeable distribution change",
                "High ‚Äî significant behaviour change",
                "Severe ‚Äî major market disruption",
                "Extreme ‚Äî complete distribution shift"
            ],
            "Real-World Analogy": [
                "Model just deployed",
                "1-2 months after deployment",
                "3-4 months after deployment",
                "5-6 months after deployment",
                "Post-price-hike scenario",
                "Post-competitor-entry scenario",
                "Full market disruption"
            ]
        })
        st.dataframe(drift_levels, use_container_width=True, hide_index=True)

    # Visual: Before vs After Drift
    st.markdown("### üìà Visualising What Drift Looks Like")
    st.markdown("The chart below shows how a feature's distribution changes at different drift magnitudes ‚Äî this is exactly what was applied to your test data.")

    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    fig.patch.set_facecolor('#1e1e1e')

    np.random.seed(42)
    original = np.random.normal(loc=65, scale=20, size=1000)  # simulate MonthlyCharges

    for idx, (mag, title, col) in enumerate(zip(
        [0.0, 0.3, 1.0],
        ["No Drift (Baseline)\nMagnitude = 0.0", "Moderate Drift\nMagnitude = 0.3", "Extreme Drift\nMagnitude = 1.0"],
        ['#3b82f6', '#f59e0b', '#ef4444']
    )):
        ax = axes[idx]
        ax.set_facecolor('#1f2937')
        noise = np.random.normal(0, 1, size=1000)
        drifted = original + (mag * np.std(original) * noise) + (mag * np.mean(original) * 0.1)
        ax.hist(original, bins=30, alpha=0.4, color='#9ca3af', label='Original', density=True)
        ax.hist(drifted, bins=30, alpha=0.7, color=col, label='Drifted', density=True)
        ax.set_title(title, color='white', fontsize=10, fontweight='bold')
        ax.set_xlabel('MonthlyCharges ($)', color='white', fontsize=9)
        ax.set_ylabel('Density', color='white', fontsize=9)
        ax.tick_params(colors='white', labelsize=8)
        for spine in ax.spines.values():
            spine.set_color('#444')
        ax.legend(fontsize=8, facecolor='#2d2d2d', labelcolor='white')

    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

    st.markdown("---")

    # --- STEP 3: Models ---
    st.markdown("## Step 3 ‚Äî Models Evaluated")

    model_info = {
        "Model": ["Logistic Regression", "Random Forest", "XGBoost", "SVM"],
        "Type": ["Linear", "Ensemble (Bagging)", "Ensemble (Boosting)", "Kernel-based"],
        "Why Included": [
            "Linear baseline ‚Äî expected to be sensitive to feature shift",
            "Tree-based ‚Äî expected robustness via feature averaging",
            "Gradient boosting ‚Äî state-of-the-art, drift behaviour unknown",
            "Margin-based ‚Äî no probability calibration, interesting drift response"
        ],
        "Hypothesis": [
            "Most sensitive to drift",
            "Moderately robust",
            "Most robust due to boosting",
            "Unpredictable ‚Äî depends on support vectors"
        ]
    }
    st.dataframe(pd.DataFrame(model_info), use_container_width=True, hide_index=True)

    st.markdown("---")

    # --- STEP 4: Evaluation ---
    st.markdown("## Step 4 ‚Äî How We Determined the Best Model")

    st.markdown("""
    <div class='alert-orange'>
        <h4 style='color:#fed7aa !important; margin:0 0 0.5rem 0;'>üèÜ The Robustness Score ‚Äî Our Key Innovation</h4>
        <p style='color:#ffedd5 !important; margin:0;'>
        We don't just compare accuracy. We measure <b>degradation % under drift</b> ‚Äî 
        which tells us how <i>stable</i> a model is as real-world data changes.
        A model with slightly lower baseline accuracy but much lower degradation is 
        <b>more valuable in production</b> than one with high accuracy that collapses under drift.
        </p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### üìê Degradation Formula")
        st.markdown("""
        <div class='method-step'>
            <p style='color:#c4b5fd !important; font-family:monospace; font-size:0.95rem; margin:0;'>
            Degradation % = ((Baseline Acc ‚àí Drifted Acc) / Baseline Acc) √ó 100
            </p>
            <p style='color:#ede9fe !important; margin:0.5rem 0 0 0; font-size:0.85rem;'>
            ‚Ä¢ <b>Negative value</b> = model actually improved under drift (unusual)<br>
            ‚Ä¢ <b>0%</b> = perfectly robust ‚Äî no degradation<br>
            ‚Ä¢ <b>Positive value</b> = model degraded ‚Äî lower is better<br>
            ‚Ä¢ Drifted Accuracy = accuracy at <b>maximum drift magnitude</b>
            </p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("### üèÖ Model Selection Criteria")
        st.markdown("""
        <div class='method-step'>
            <p style='color:#fde68a !important; font-weight:700; margin:0 0 0.5rem 0;'>A model is recommended for production when it has:</p>
            <p style='color:#fef3c7 !important; margin:0; font-size:0.9rem;'>
            ‚úÖ <b>High baseline accuracy</b> (competitive performance)<br><br>
            ‚úÖ <b>Low degradation %</b> under maximum drift (stable)<br><br>
            ‚úÖ <b>Consistent performance curve</b> (no sudden drops)<br><br>
            ‚úÖ <b>Early detectability</b> via KS test / PSI thresholds
            </p>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")
    st.markdown("""
    <div class='alert-green'>
        <h4 style='color:#6ee7b7 !important; margin:0 0 0.5rem 0;'>‚úÖ Summary: What Makes This Methodology Rigorous</h4>
        <p style='color:#d1fae5 !important; margin:0;'>
        1. <b>Controlled drift</b> ‚Äî we vary magnitude from 0.0 to 1.0 in 7 increments, isolating the drift effect<br>
        2. <b>Multiple drift types</b> ‚Äî covariate, prior, and concept drift all tested<br>
        3. <b>Multiple models</b> ‚Äî 4 architecturally different models compared fairly<br>
        4. <b>Multiple metrics</b> ‚Äî accuracy, precision, recall, F1 all tracked<br>
        5. <b>Statistical detection</b> ‚Äî KS test and PSI used to detect drift objectively
        </p>
    </div>
    """, unsafe_allow_html=True)


# ===========================================================
# PAGE: LIVE PREDICTION
# ===========================================================
elif page == "üîÆ Live Prediction":
    st.title("üîÆ Customer Churn Prediction")

    @st.cache_resource
    def load_models():
        try:
            base_path = os.getcwd()
            model = joblib.load(os.path.join(base_path, 'xgb_model.pkl'))
            le_contract = joblib.load(os.path.join(base_path, 'le_contract.pkl'))
            le_internet = joblib.load(os.path.join(base_path, 'le_internet.pkl'))
            return model, le_contract, le_internet, None
        except Exception as e:
            return None, None, None, str(e)

    model, le_contract, le_internet, error = load_models()

    if error:
        st.error(f"‚ùå Error loading models: {error}")
        st.info("Make sure you're running from the project directory")

    if model:
        col1, col2 = st.columns(2)
        with col1:
            tenure = st.slider("üìÖ Tenure (Months)", 0, 72, 12)
            contract = st.selectbox("üìÑ Contract Type", ["Month-to-month", "One year", "Two year"])
        with col2:
            monthly_charges = st.slider("üí∞ Monthly Charges ($)", 20.0, 120.0, 70.0)
            internet_service = st.selectbox("üåê Internet Service", ["DSL", "Fiber optic", "No"])

        threshold = st.slider("‚öñÔ∏è Risk Threshold", 0.1, 0.9, 0.5, 0.05)

        if st.button("üöÄ Predict Churn Risk", type="primary"):
            try:
                total_charges = tenure * monthly_charges
                contract_encoded = le_contract.transform([contract])[0]
                internet_encoded = le_internet.transform([internet_service])[0]
                input_data = np.array([[tenure, monthly_charges, total_charges, contract_encoded, internet_encoded]])
                probability = model.predict_proba(input_data)[0][1]

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Churn Probability", f"{probability:.2%}")
                with col2:
                    if probability >= threshold:
                        st.error("‚ùå Likely to Churn")
                    else:
                        st.success("‚úÖ Likely to Stay")
                with col3:
                    st.metric("Confidence", f"{max(probability, 1-probability):.2%}")

                st.progress(float(probability))

                if probability < 0.3:
                    st.success("üü¢ Low Risk - Customer stable")
                elif probability < 0.7:
                    st.warning("üü° Medium Risk - Monitor closely")
                else:
                    st.error("üî¥ High Risk - Immediate action needed")
            except Exception as e:
                st.error(f"Error: {e}")
    else:
        st.error("Models not found. Run from project directory.")


# ===========================================================
# PAGE: RESEARCH RESULTS (Improved axis labels + annotations)
# ===========================================================
elif page == "üìà Research Results":
    st.title("üìà Experimental Results")
    st.markdown("*How model accuracy changes as data drift magnitude increases from 0.0 (no drift) to 1.0 (extreme drift)*")

    try:
        results = pd.read_csv('results/experiments/covariate_drift_results.csv')

        col1, col2 = st.columns(2)
        with col1:
            models_list = st.multiselect(
                "Select Models",
                results['model'].unique(),
                default=list(results['model'].unique())
            )
        with col2:
            metric = st.selectbox("Metric", ['accuracy', 'precision', 'recall', 'f1_score'])

        # Key insight callout
        st.markdown("""
        <div class='alert-blue'>
            <p style='color:#bfdbfe !important; margin:0; font-size:0.9rem;'>
            üìå <b>How to read this chart:</b> The X-axis shows drift magnitude ‚Äî 0.0 means the original test data (no drift),
            1.0 means extreme distribution shift. A flat line = robust model. A steep downward slope = sensitive to drift.
            </p>
        </div>
        """, unsafe_allow_html=True)

        fig, ax = plt.subplots(figsize=(12, 6))
        fig.patch.set_facecolor('#1e1e1e')
        ax.set_facecolor('#1e1e1e')

        for model_name in models_list:
            data = results[results['model'] == model_name].sort_values('drift_magnitude')
            ax.plot(data['drift_magnitude'], data[metric], marker='o',
                    label=model_name, linewidth=2.5, markersize=8)

        # Drift zone annotations
        ax.axvspan(0.0, 0.2, alpha=0.05, color='green', label='_nolegend_')
        ax.axvspan(0.2, 0.6, alpha=0.05, color='yellow', label='_nolegend_')
        ax.axvspan(0.6, 1.0, alpha=0.05, color='red', label='_nolegend_')

        ax.text(0.01, ax.get_ylim()[0] + 0.001, 'üü¢ Mild Drift', color='#4ade80', fontsize=8, alpha=0.8)
        ax.text(0.22, ax.get_ylim()[0] + 0.001, 'üü° Moderate Drift', color='#fbbf24', fontsize=8, alpha=0.8)
        ax.text(0.62, ax.get_ylim()[0] + 0.001, 'üî¥ Severe Drift', color='#f87171', fontsize=8, alpha=0.8)

        ax.set_xlabel('Drift Magnitude  (0.0 = No Drift ‚Üí 1.0 = Extreme Drift)', fontsize=12, color='white')
        ax.set_ylabel(metric.replace('_', ' ').title(), fontsize=12, color='white')
        ax.set_title(f'Model Performance Under Covariate Drift ‚Äî {metric.replace("_", " ").title()}',
                     fontsize=14, fontweight='bold', color='white')
        ax.legend(fontsize=10, facecolor='#2d2d2d', labelcolor='white')
        ax.tick_params(colors='white')
        for spine in ax.spines.values():
            spine.set_color('#444')
        ax.grid(True, alpha=0.2, color='white')
        st.pyplot(fig)
        plt.close()

        # Summary stats below chart
        st.markdown("### üìä Performance Summary Table")
        st.markdown("*Baseline = drift magnitude 0.0 | Drifted = drift magnitude at maximum*")

        baseline = results[results['drift_magnitude'] == 0.0]
        high_drift = results[results['drift_magnitude'] == results['drift_magnitude'].max()]

        summary_rows = []
        for m in results['model'].unique():
            b = baseline[baseline['model'] == m]
            d = high_drift[high_drift['model'] == m]
            if not b.empty and not d.empty:
                summary_rows.append({
                    'Model': m,
                    f'Baseline {metric.title()}': round(b.iloc[0][metric], 4),
                    f'Drifted {metric.title()}': round(d.iloc[0][metric], 4),
                    'Change': round(d.iloc[0][metric] - b.iloc[0][metric], 4)
                })

        summary_df = pd.DataFrame(summary_rows)
        st.dataframe(summary_df, use_container_width=True, hide_index=True)

    except Exception as e:
        st.error(f"Error loading results: {e}")
        st.info("Make sure covariate_drift_results.csv exists in results/experiments/")


# ===========================================================
# PAGE: MODEL ROBUSTNESS (Improved with clear recommendation)
# ===========================================================
elif page == "üéØ Model Robustness":
    st.title("üéØ Model Robustness Comparison")

    try:
        results = pd.read_csv('results/experiments/covariate_drift_results.csv')
        baseline = results[results['drift_magnitude'] == 0.0]
        high_drift = results[results['drift_magnitude'] == results['drift_magnitude'].max()]

        comparison = []
        for model_name in baseline['model'].unique():
            base = baseline[baseline['model'] == model_name].iloc[0]
            drift = high_drift[high_drift['model'] == model_name].iloc[0]
            comparison.append({
                'Model': model_name,
                'Baseline Accuracy': round(base['accuracy'], 4),
                'Drifted Accuracy': round(drift['accuracy'], 4),
                'Degradation %': round((base['accuracy'] - drift['accuracy']) / base['accuracy'] * 100, 2)
            })

        df = pd.DataFrame(comparison).sort_values('Degradation %')
        best_model = df.iloc[0]
        worst_model = df.iloc[-1]

        st.markdown("**Lower degradation = More robust to drift**")
        st.dataframe(
            df.style.background_gradient(subset=['Degradation %'], cmap='RdYlGn_r')
              .format({'Degradation %': '{:.2f}%'}),
            use_container_width=True
        )

        fig, ax = plt.subplots(figsize=(10, 5))
        fig.patch.set_facecolor('#1e1e1e')
        ax.set_facecolor('#1e1e1e')
        bar_colors = ['#22c55e' if x <= df['Degradation %'].median() else '#ef4444' for x in df['Degradation %']]
        bars = ax.barh(df['Model'], df['Degradation %'], color=bar_colors)
        ax.set_xlabel('Degradation % (Lower = More Robust)', color='white', fontsize=11)
        ax.set_title('Model Robustness Under Maximum Drift (Lower is Better)', color='white',
                     fontweight='bold', fontsize=13)
        ax.tick_params(colors='white')
        for spine in ax.spines.values():
            spine.set_color('#444')
        ax.grid(True, axis='x', alpha=0.2, color='white')

        for bar, val in zip(bars, df['Degradation %']):
            ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                    f'{val:.2f}%', va='center', color='white', fontsize=10)

        green_patch = mpatches.Patch(color='#22c55e', label='‚â§ Median Degradation (Robust)')
        red_patch = mpatches.Patch(color='#ef4444', label='> Median Degradation (Sensitive)')
        ax.legend(handles=[green_patch, red_patch], facecolor='#2d2d2d', labelcolor='white', fontsize=9)

        st.pyplot(fig)
        plt.close()

        # SVM warning ‚Äî degenerate classifier
        has_svm = 'SVM' in df['Model'].values

        st.markdown("---")

        # SVM Critical Finding callout
        if has_svm:
            st.markdown("""
            <div class='alert-orange'>
                <h4 style='color:#fed7aa !important; margin:0 0 0.5rem 0;'>‚ö†Ô∏è Critical Finding: SVM Degenerate Behaviour Detected</h4>
                <p style='color:#ffedd5 !important; margin:0; font-size:0.9rem;'>
                SVM shows <b>0.00% degradation</b> ‚Äî but this is <b>misleading</b>. Its precision, recall, and F1-score
                are <b>all 0.0</b> across every drift level, meaning it collapsed to predicting only the majority class
                (accuracy ‚âà 73.5% = majority class baseline). SVM's "robustness" is actually a <b>total model failure</b>,
                not resilience. This is a key research finding: <i>accuracy alone is insufficient to evaluate model robustness under drift.</i>
                </p>
            </div>
            """, unsafe_allow_html=True)

        st.success(f"‚úÖ Most Robust (genuine): **Logistic Regression** (-1.18% ‚Äî accuracy slightly improved under drift)")
        st.warning(f"‚ö†Ô∏è SVM: 0.00% degradation but **degenerate** ‚Äî predicts only majority class, F1 = 0.0")
        st.error(f"‚ùå Least Robust: **Random Forest** (1.31% accuracy drop, F1 collapses from 0.519 ‚Üí 0.385)")

        # ---- CLEAR RECOMMENDATION ----
        st.markdown("---")
        st.markdown("## üèÜ Model Recommendation")

        st.markdown("""
        <div class='recommendation-box'>
            <h3 style='color:#6ee7b7 !important; margin:0 0 1rem 0;'>
                ‚úÖ Recommended for Production: Logistic Regression
            </h3>
            <p style='color:#d1fae5 !important; margin:0 0 0.8rem 0; font-size:1rem;'>
            Based on our empirical analysis across <b>7 drift magnitudes (0.0 ‚Üí 1.0)</b> and
            <b>4 metrics</b> (accuracy, precision, recall, F1),
            <b>Logistic Regression</b> is the recommended model for deployment in
            drift-prone production environments such as telco customer churn prediction.
            </p>
            <p style='color:#d1fae5 !important; margin:0; font-size:0.95rem;'>
            üìå <b>Justification:</b><br>
            ‚Ä¢ <b>Only model that improved</b> under drift: accuracy went from 0.7793 ‚Üí 0.7885 (+1.18%)<br>
            ‚Ä¢ Highest baseline accuracy tied with XGBoost: <b>0.7793</b><br>
            ‚Ä¢ Consistent F1-score across all drift levels (0.541 ‚Üí 0.516) ‚Äî no sudden collapse<br>
            ‚Ä¢ Highest ROC-AUC at max drift: <b>0.8221</b> ‚Äî best discrimination ability under stress<br>
            ‚Ä¢ Interpretable ‚Äî coefficients can explain <i>why</i> predictions change under drift
            </p>
        </div>
        """, unsafe_allow_html=True)

        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("""
            <div class='finding-card'>
                <h4 style='color:#60a5fa !important; margin:0 0 0.5rem 0;'>‚úÖ Use Logistic Regression when:</h4>
                <p style='color:#e0e0e0 !important; font-size:0.9rem; margin:0;'>
                ‚Ä¢ Long deployment cycles (6+ months)<br>
                ‚Ä¢ Limited retraining budget<br>
                ‚Ä¢ Interpretability is required<br>
                ‚Ä¢ Data drifts gradually over time
                </p>
            </div>
            """, unsafe_allow_html=True)
        with col2:
            st.markdown("""
            <div class='finding-card'>
                <h4 style='color:#fbbf24 !important; margin:0 0 0.5rem 0;'>‚ö° XGBoost as runner-up:</h4>
                <p style='color:#e0e0e0 !important; font-size:0.9rem; margin:0;'>
                ‚Ä¢ 1.09% degradation ‚Äî acceptable<br>
                ‚Ä¢ Better recall than LR under drift<br>
                ‚Ä¢ Use when <b>catching churners</b><br>&nbsp;&nbsp;matters more than precision<br>
                ‚Ä¢ Good if retraining is frequent
                </p>
            </div>
            """, unsafe_allow_html=True)
        with col3:
            st.markdown("""
            <div class='finding-card'>
                <h4 style='color:#f87171 !important; margin:0 0 0.5rem 0;'>‚ùå Avoid Random Forest when:</h4>
                <p style='color:#e0e0e0 !important; font-size:0.9rem; margin:0;'>
                ‚Ä¢ Data distributions shift over time<br>
                ‚Ä¢ Intervals between retraining are long<br>
                ‚Ä¢ F1-score matters (drops 26% at max drift)<br>
                ‚Ä¢ Market is volatile or seasonal
                </p>
            </div>
            """, unsafe_allow_html=True)

        # Retraining threshold guidance
        st.markdown("### ‚è∞ When Should You Retrain? ‚Äî Thresholds from This Study")
        threshold_data = pd.DataFrame({
            "Drift Magnitude Detected": ["0.0 ‚Äì 0.2", "0.2 ‚Äì 0.5", "0.5 ‚Äì 0.7", "0.7 ‚Äì 1.0"],
            "Action": ["‚úÖ No action needed", "üëÄ Monitor F1-score weekly", "‚ö†Ô∏è Schedule retraining", "üö® Retrain immediately"],
            "What Our Data Shows": [
                "All models stable ‚Äî accuracy within 0.5% of baseline",
                "Random Forest F1 starts dropping noticeably (0.519 ‚Üí 0.456)",
                "Random Forest F1 at 0.460, XGBoost at 0.487 ‚Äî meaningful degradation",
                "Random Forest F1 collapsed to 0.385 ‚Äî 26% drop. Retrain urgently."
            ],
            "Best Model at This Stage": [
                "Any ‚Äî all perform similarly",
                "Logistic Regression or XGBoost",
                "Logistic Regression (most stable F1)",
                "Logistic Regression only reliable option"
            ]
        })
        st.dataframe(threshold_data, use_container_width=True, hide_index=True)

        # F1 score collapse chart ‚Äî shows the real story
        st.markdown("### üìâ F1-Score Collapse Under Drift ‚Äî The Real Story")
        st.markdown("*Accuracy hides the truth. F1-score reveals which models are truly failing.*")

        try:
            results_full = pd.read_csv('results/experiments/covariate_drift_results.csv')
            fig2, ax2 = plt.subplots(figsize=(12, 5))
            fig2.patch.set_facecolor('#1e1e1e')
            ax2.set_facecolor('#1e1e1e')

            model_colors = {'Logistic Regression': '#3b82f6', 'Random Forest': '#f97316',
                           'XGBoost': '#22c55e', 'SVM': '#a855f7'}

            for model_name in results_full['model'].unique():
                data = results_full[results_full['model'] == model_name].sort_values('drift_magnitude')
                style = '--' if model_name == 'SVM' else '-'
                ax2.plot(data['drift_magnitude'], data['f1_score'], marker='o',
                        label=model_name, linewidth=2.5, markersize=7,
                        color=model_colors.get(model_name, 'white'), linestyle=style)

            ax2.set_xlabel('Drift Magnitude (0.0 = No Drift ‚Üí 1.0 = Extreme Drift)', fontsize=11, color='white')
            ax2.set_ylabel('F1-Score', fontsize=11, color='white')
            ax2.set_title('F1-Score Under Drift ‚Äî SVM Collapses to 0, Random Forest Degrades Most',
                         fontsize=12, fontweight='bold', color='white')
            ax2.legend(fontsize=10, facecolor='#2d2d2d', labelcolor='white')
            ax2.tick_params(colors='white')
            for spine in ax2.spines.values():
                spine.set_color('#444')
            ax2.grid(True, alpha=0.2, color='white')
            ax2.annotate('SVM: F1=0 across all\ndrift levels ‚Äî degenerate',
                        xy=(0.5, 0.01), xytext=(0.3, 0.12),
                        arrowprops=dict(arrowstyle='->', color='#a855f7'),
                        color='#a855f7', fontsize=9)
            st.pyplot(fig2)
            plt.close()
        except:
            pass

    except Exception as e:
        st.error(f"Error: {e}")
        st.info("Run experiments first")


# ===========================================================
# PAGE: INDUSTRY VALUE
# ===========================================================
elif page == "üíº Industry Value":
    st.title("üíº Industry Impact & Application")

    st.markdown("""
    <div style='background:#1e3a5f; border:2px solid #3b82f6; border-radius:10px; padding:1.5rem; margin:1rem 0;'>
        <h4 style='color:#93c5fd !important; margin:0 0 0.5rem 0;'>üéØ Real-World Problem Addressed</h4>
        <p style='color:#bfdbfe !important; margin:0;'>
        73% of ML models experience significant performance degradation within 6 months due to data drift.
        This costs enterprises an estimated <b>$15 billion annually</b> in lost revenue and poor decisions.
        </p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### üè≠ Production Challenges")
        st.markdown("""
        - **Silent Failures**: Models degrade without alerting teams
        - **No Baselines**: Lack of degradation benchmarks
        - **Reactive Monitoring**: Issues found after damage
        - **Inefficient Retraining**: Models retrained too early/late
        """)
        st.markdown("### üé§ Interview Answer")
        st.markdown("""
        > *"I studied how 4 ML models respond to covariate drift in a telco churn dataset.
        I simulated drift using Gaussian noise injection and mean shift on all numeric features,
        testing 7 drift magnitudes from 0.0 to 1.0.
        My key finding was that accuracy is misleading under drift ‚Äî SVM appeared 0% degraded
        but actually collapsed to predicting only the majority class with F1 of 0.
        Logistic Regression was genuinely the most robust, actually improving slightly under drift
        while maintaining consistent F1-scores. Random Forest was least robust, with F1 dropping
        26% at maximum drift. This shows that model selection for production should prioritise
        degradation robustness, not just baseline accuracy."*
        """)
    with col2:
        st.markdown("### üí° Practical Applications")
        st.markdown("""
        **For ML Engineers:**
        - Choose robust models for drift-prone domains
        - Set monitoring thresholds based on research findings

        **For Data Scientists:**
        - Design drift-resilient features
        - Optimise retraining schedules using degradation curves

        **For Business:**
        - Predict when models need updating
        - Reduce emergency interventions and silent failures
        """)


# ===========================================================
# PDF REPORT GENERATION
# ===========================================================
def generate_pdf_report(results_df):
    pdf_path = "ML_Data_Drift_Report.pdf"
    doc = SimpleDocTemplate(pdf_path, pagesize=A4)
    elements = []
    styles = getSampleStyleSheet()

    elements.append(Paragraph("<b>Data Drift Impact on ML Model Performance</b>", styles["Title"]))
    elements.append(Spacer(1, 0.3 * inch))
    elements.append(Paragraph(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles["Normal"]))
    elements.append(Spacer(1, 0.3 * inch))

    elements.append(Paragraph("<b>Methodology Summary</b>", styles["Heading2"]))
    elements.append(Spacer(1, 0.2 * inch))
    elements.append(Paragraph(
        "Covariate drift was simulated using Gaussian noise injection combined with a mean shift "
        "applied to all numeric features (tenure, MonthlyCharges, TotalCharges). "
        "Drift magnitudes from 0.0 to 1.0 were tested in 7 levels. "
        "Models were evaluated on accuracy, precision, recall, and F1-score at each drift level. "
        "The primary evaluation metric is Degradation % ‚Äî the percentage drop in accuracy "
        "from baseline to maximum drift.",
        styles["Normal"]
    ))
    elements.append(Spacer(1, 0.4 * inch))

    elements.append(Paragraph("<b>Executive Summary</b>", styles["Heading2"]))
    elements.append(Spacer(1, 0.2 * inch))

    baseline = results_df[results_df['drift_magnitude'] == 0.0]
    high_drift = results_df[results_df['drift_magnitude'] == results_df['drift_magnitude'].max()]
    avg_drop = round((baseline['accuracy'].mean() - high_drift['accuracy'].mean()) * 100, 2)

    summary_text = (
        f"Total Models Tested: {results_df['model'].nunique()}<br/>"
        f"Total Experiments Conducted: {len(results_df)}<br/>"
        f"Maximum Drift Level Tested: {results_df['drift_magnitude'].max()}<br/>"
        f"Average Performance Drop at Max Drift: {avg_drop}%"
    )
    elements.append(Paragraph(summary_text, styles["Normal"]))
    elements.append(Spacer(1, 0.4 * inch))

    elements.append(Paragraph("<b>Model Robustness Comparison</b>", styles["Heading2"]))
    elements.append(Spacer(1, 0.2 * inch))

    comparison_data = [["Model", "Baseline Acc", "Drifted Acc", "Degradation %", "Recommendation"]]

    model_results = []
    for model_name in baseline['model'].unique():
        base = baseline[baseline['model'] == model_name].iloc[0]
        drift = high_drift[high_drift['model'] == model_name].iloc[0]
        degradation = round((base['accuracy'] - drift['accuracy']) / base['accuracy'] * 100, 2)
        model_results.append((model_name, round(base['accuracy'], 4), round(drift['accuracy'], 4), degradation))

    model_results.sort(key=lambda x: x[3])
    best = model_results[0][0]

    for idx, (mn, ba, da, deg) in enumerate(model_results):
        rec = "‚úì RECOMMENDED" if idx == 0 else ("‚úó Avoid in prod" if idx == len(model_results)-1 else "Acceptable")
        comparison_data.append([mn, ba, da, f"{deg}%", rec])

    table = Table(comparison_data, repeatRows=1)
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.darkblue),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
        ('BACKGROUND', (0, 1), (-1, -1), colors.whitesmoke),
        ('BACKGROUND', (0, 1), (-1, 1), colors.lightgreen),
    ]))
    elements.append(table)
    elements.append(Spacer(1, 0.3 * inch))
    elements.append(Paragraph(
        f"<b>Recommendation: {best}</b> is the most robust model for production deployment "
        f"in drift-prone environments, demonstrating the lowest accuracy degradation under maximum drift.",
        styles["Normal"]
    ))
    elements.append(PageBreak())

    elements.append(Paragraph("<b>Model Performance Curves Under Drift</b>", styles["Heading2"]))
    elements.append(Spacer(1, 0.3 * inch))

    for model_name in results_df['model'].unique():
        fig, ax = plt.subplots(figsize=(6, 4))
        model_data = results_df[results_df['model'] == model_name].sort_values('drift_magnitude')
        ax.plot(model_data['drift_magnitude'], model_data['accuracy'], marker='o', linewidth=2)
        ax.set_title(f"{model_name} ‚Äî Accuracy vs Drift Magnitude")
        ax.set_xlabel("Drift Magnitude (0.0 = No Drift ‚Üí 1.0 = Extreme Drift)")
        ax.set_ylabel("Accuracy")
        ax.grid(True)
        image_path = f"{model_name}_drift_plot.png"
        fig.savefig(image_path, dpi=150, bbox_inches='tight')
        plt.close(fig)
        elements.append(Paragraph(f"{model_name} Performance Curve", styles["Heading3"]))
        elements.append(Spacer(1, 0.2 * inch))
        elements.append(RLImage(image_path, width=5.5 * inch, height=3.5 * inch))
        elements.append(Spacer(1, 0.5 * inch))

    elements.append(PageBreak())
    elements.append(Paragraph("<b>Research Conclusion</b>", styles["Heading2"]))
    elements.append(Spacer(1, 0.2 * inch))
    elements.append(Paragraph(
        "This study empirically demonstrates that ML models degrade under covariate drift simulated via "
        "Gaussian noise injection and mean shift on numeric features. The key finding is that model "
        "robustness ‚Äî measured by degradation % rather than absolute accuracy ‚Äî varies significantly "
        "across architectures. The recommended production model is the one with the lowest degradation "
        "percentage, indicating it will remain reliable longest between retraining cycles. "
        "Organisations should use the degradation thresholds identified in this study to set automated "
        "retraining triggers in their ML monitoring pipelines.",
        styles["Normal"]
    ))

    doc.build(elements)
    return pdf_path


# ---- FOOTER + PDF DOWNLOAD ----
st.markdown("---")
st.markdown("""
<p style='text-align:center; color:#6b7280; font-size:0.85rem;'>
üìä NCI Master's Project | Data Mining & ML 2026 | Empirical Study of ML Model Performance Under Data Drift
</p>
""", unsafe_allow_html=True)

try:
    if os.path.exists('results/experiments/covariate_drift_results.csv'):
        results = pd.read_csv('results/experiments/covariate_drift_results.csv')
        st.markdown("---")
        st.markdown("## üìÑ Download Full Model Performance Report")
        if st.button("üì• Generate & Download PDF Report"):
            pdf_path = generate_pdf_report(results)
            with open(pdf_path, "rb") as f:
                st.download_button(
                    label="‚¨áÔ∏è Click Here to Download Report",
                    data=f,
                    file_name="ML_Data_Drift_Report.pdf",
                    mime="application/pdf"
                )
except:
    pass

